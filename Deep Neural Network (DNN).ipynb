{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Model Building & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import gradio as gr\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from numpy import mean, std\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Loading dataset from MNIST package & assign to train test variables\n",
    "    (trainx, trainy), (testx, testy) = mnist.load_data()\n",
    "    # Reshaping pixels into single array for DL model input layer\n",
    "    trainx = trainx.reshape((-1, 28, 28, 1))\n",
    "    testx = testx.reshape((-1, 28, 28, 1))\n",
    "    # One Hot Encoding (OHE) for labels\n",
    "    trainy = to_categorical(trainy)\n",
    "    \n",
    "    return trainx, trainy, testx, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy, testx, testy = data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation & Normalize Pixels (only for train & test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_transforming():\n",
    "    # convert from integers to floats\n",
    "    train_norm = trainx.astype('float32')\n",
    "    test_norm = testx.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx = pixels_transforming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout reqularization is a computationally cheap way to regularize deep neural network. Also reduces overfitting.\n",
    "\n",
    "def model_building(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    # VGG Block 1 (input format 28x28 pixels) + padding\n",
    "    model.add(Conv2D(hp.Int('inputs',\n",
    "                            min_value=32,\n",
    "                            max_value=256,\n",
    "                            step=32),\n",
    "                     (3, 3), padding='same',\n",
    "                     activation='relu',\n",
    "                     kernel_initializer='he_uniform', \n",
    "                     input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Choice('drops', [0.1,0.2,0.3])))\n",
    "#     # VGG Block 2 + padding (increased filters)\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     # VGG Block 3 + padding (increased filters)\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # hidden layers\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10, step=1)):\n",
    "        model.add(Dense(hp.Int('num_nodes',\n",
    "                               min_value=32,\n",
    "                               max_value=256,\n",
    "                               step=32),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dropout(hp.Choice('drops', [0.1,0.2,0.3])))\n",
    "    \n",
    "    # output layer: if binary classification, use 1 layer and sigmoid activation\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    # if binary classification, loss is binary_crossentropy\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter Tuning (using GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tuning():\n",
    "    tuner = RandomSearch(model_building,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials=5,\n",
    "                     directory=os.path.normpath('C:/MNIST Digits Classification'),\n",
    "                     executions_per_trial=3,\n",
    "                     project_name='MNIST Digit Keras Tuner')\n",
    "    tuner.search_space_summary()\n",
    "    # if doesn't run, please delete pre-load runs from above directory\n",
    "    tuner.search(trainx, trainy, epochs=5, batch_size=64, validation_split=0.2, shuffle=True)\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = model_tuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Best Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define DNN model network using best parameters from Keras Tuner & continue with model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    # VGG Block 1 (input format 28x28 pixels) + padding\n",
    "    model.add(Conv2D(192, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # hidden layers\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # output layer: if binary classification, use 1 layer and sigmoid activation\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    # if binary classification, loss is binary_crossentropy\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(trainx, trainy, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    #save best model\n",
    "    model.save('final_model_deploy.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Testing (on test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing():\n",
    "    model_pred = final_model.predict_classes(testx)\n",
    "    print('Accuracy :', accuracy_score(testy, model_pred), '\\n')\n",
    "    print('Confusion Matrix :\\n', confusion_matrix(testy, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9703 \n",
      "\n",
      "Confusion Matrix :\n",
      " [[ 966    0    0    0    0    1    3    1    9    0]\n",
      " [   0 1120    2    5    0    0    0    1    7    0]\n",
      " [   2    0  992   11    4    0    2    9   11    1]\n",
      " [   0    0    3  979    0   12    0    3    2   11]\n",
      " [   0    0    1    0  936    0    6   13   12   14]\n",
      " [   5    0    0    4    0  852    9    1    3   18]\n",
      " [  11    3    0    0    0    1  934    1    8    0]\n",
      " [   0    0    8    8    0    0    0 1004    5    3]\n",
      " [   3    0    3    2    1    2    1    6  954    2]\n",
      " [   4    3    0    1    3    4    1   17   10  966]]\n"
     ]
    }
   ],
   "source": [
    "model_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Model Live Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c50ce36c08>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tensorflow.keras.models.load_model(\"final_model_deploy.h5\")\n",
    "\n",
    "def recognize_digit(image):\n",
    "    image = image.reshape(1, -1)  # add a batch dimension\n",
    "    prediction = model.predict(image).tolist()[0]\n",
    "    return {str(i): prediction[i] for i in range(10)}\n",
    "\n",
    "output_component = gr.outputs.Label(num_top_classes=3)\n",
    "\n",
    "gr.Interface(fn=recognize_digit, \n",
    "             inputs=\"sketchpad\", \n",
    "             outputs=output_component,\n",
    "             live=True,\n",
    "             title=\"MNIST Sketchpad\",\n",
    "             description=\"Draw a number 0 through 9 on the sketchpad, and click submit to see the model's predictions. Model trained on the MNIST dataset.\",\n",
    "             thumbnail=\"https://raw.githubusercontent.com/gradio-app/real-time-mnist/master/thumbnail2.png\").launch();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
